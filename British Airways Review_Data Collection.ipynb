{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b08be2",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c0858",
   "metadata": {},
   "source": [
    "We will be looking at the review data on the website called [Skytrax](https://www.airlinequality.com/airline-reviews/british-airways) and will collect the data about the airline review, the rating given bu the customer etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c5d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to be imported\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cbae18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the empty lists to collect the data\n",
    "\n",
    "reviews = []\n",
    "rating = []\n",
    "date = []\n",
    "country = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96292298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping page: 1\n",
      "Scrapping page: 2\n",
      "Scrapping page: 3\n",
      "Scrapping page: 4\n",
      "Scrapping page: 5\n",
      "Scrapping page: 6\n",
      "Scrapping page: 7\n",
      "Scrapping page: 8\n",
      "Scrapping page: 9\n",
      "Scrapping page: 10\n",
      "Scrapping page: 11\n",
      "Scrapping page: 12\n",
      "Scrapping page: 13\n",
      "Scrapping page: 14\n",
      "Scrapping page: 15\n",
      "Scrapping page: 16\n",
      "Scrapping page: 17\n",
      "Scrapping page: 18\n",
      "Scrapping page: 19\n",
      "Scrapping page: 20\n",
      "Scrapping page: 21\n",
      "Scrapping page: 22\n",
      "Scrapping page: 23\n",
      "Scrapping page: 24\n",
      "Scrapping page: 25\n",
      "Scrapping page: 26\n",
      "Scrapping page: 27\n",
      "Scrapping page: 28\n",
      "Scrapping page: 29\n",
      "Scrapping page: 30\n",
      "             Error on page: 30\n",
      "Scrapping page: 31\n",
      "             Error on page: 31\n",
      "             Error on page: 31\n",
      "Scrapping page: 32\n",
      "Scrapping page: 33\n",
      "Scrapping page: 34\n",
      "             Error on page: 34\n",
      "             Error on page: 34\n",
      "Scrapping page: 35\n"
     ]
    }
   ],
   "source": [
    "# Data collection\n",
    "\n",
    "for i in range(1,36):\n",
    "    print(f\"Scrapping page: {i}\")\n",
    "    \n",
    "    page = requests.get(f\"https://www.airlinequality.com/airline-reviews/british-airways/page/{i}/?sortby=post_date%3ADesc&pagesize=100\")\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    for item in soup.find_all(\"div\", class_=\"text_content\"):\n",
    "        reviews.append(item.text)\n",
    "        \n",
    "    for item in soup.find_all(\"div\", \"rating-10\"):\n",
    "        if 'rating-large' in item['class']:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                rating.append(item.span.text)\n",
    "            except:\n",
    "                rating.append(\"None\")\n",
    "                print(f\"             Error on page: {i}\")\n",
    "    \n",
    "    for item in soup.find_all(\"time\"):\n",
    "        date.append(item.text)\n",
    "    \n",
    "    for item in soup.find_all(\"h3\"):\n",
    "        country.append(item.span.next_sibling.text.strip(\" ()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5a5e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of reviews: 3497\n",
      "Length of rating: 3497\n",
      "Length of date: 3497\n",
      "Length of country: 3497\n"
     ]
    }
   ],
   "source": [
    "# Checking the length of the lists\n",
    "\n",
    "print(f\"Length of reviews: {len(reviews)}\")\n",
    "print(f\"Length of rating: {len(rating)}\")\n",
    "print(f\"Length of date: {len(date)}\")\n",
    "print(f\"Length of country: {len(country)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45eb61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the collected data\n",
    "\n",
    "df = pd.DataFrame({\"reviews\":reviews, \"rating\":rating, \"review date\":date, \"country\":country})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bade3a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>review date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  If I could give a minus rating...</td>\n",
       "      <td>1</td>\n",
       "      <td>15th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Plane was over an hour late ...</td>\n",
       "      <td>2</td>\n",
       "      <td>15th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  We were flying World Traveller...</td>\n",
       "      <td>2</td>\n",
       "      <td>14th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This was literally one of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>13th March 2023</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The usual shambolic unfoldi...</td>\n",
       "      <td>1</td>\n",
       "      <td>12th March 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews rating      review date  \\\n",
       "0  Not Verified |  If I could give a minus rating...      1  15th March 2023   \n",
       "1  ✅ Trip Verified | Plane was over an hour late ...      2  15th March 2023   \n",
       "2  Not Verified |  We were flying World Traveller...      2  14th March 2023   \n",
       "3  Not Verified |  This was literally one of the ...      1  13th March 2023   \n",
       "4  ✅ Trip Verified |  The usual shambolic unfoldi...      1  12th March 2023   \n",
       "\n",
       "          country  \n",
       "0  United Kingdom  \n",
       "1  United Kingdom  \n",
       "2  United Kingdom  \n",
       "3         Ireland  \n",
       "4  United Kingdom  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fae05b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3497, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the data frame\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d39c23",
   "metadata": {},
   "source": [
    "## Export the data into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82280273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f13511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder already exists\n"
     ]
    }
   ],
   "source": [
    "# Creating a data folder in the current working directory\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"data\")\n",
    "except FileExistsError:\n",
    "    print(\"The folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8b34d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the csv file in the data folder\n",
    "\n",
    "df.to_csv(\"data/BA_reviews_raw.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
